Conda uses environments to load different sets of Python packages
type conda env list to see the environments availible.
2019-04-03 14:45:55 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-04-03 14:45:59 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-04-03 14:45:59 INFO  SparkContext:54 - Submitted application: COM6012 Spark Intro
2019-04-03 14:45:59 INFO  SecurityManager:54 - Changing view acls to: acp17at
2019-04-03 14:45:59 INFO  SecurityManager:54 - Changing modify acls to: acp17at
2019-04-03 14:45:59 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-04-03 14:45:59 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-04-03 14:45:59 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acp17at); groups with view permissions: Set(); users  with modify permissions: Set(acp17at); groups with modify permissions: Set()
2019-04-03 14:45:59 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 42873.
2019-04-03 14:45:59 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-04-03 14:45:59 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-04-03 14:45:59 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-04-03 14:45:59 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-04-03 14:45:59 INFO  DiskBlockManager:54 - Created local directory at /scratch/4047101.1.rse-com6012.q/blockmgr-38963b1f-bd8a-4d89-819c-c3c75fffaf9b
2019-04-03 14:45:59 INFO  MemoryStore:54 - MemoryStore started with capacity 10.5 GB
2019-04-03 14:45:59 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-04-03 14:45:59 INFO  log:192 - Logging initialized @5401ms
2019-04-03 14:45:59 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-04-03 14:45:59 INFO  Server:419 - Started @5457ms
2019-04-03 14:45:59 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2019-04-03 14:45:59 INFO  AbstractConnector:278 - Started ServerConnector@5e7f56e0{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2019-04-03 14:45:59 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@58bdad0f{/jobs,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5bb7086c{/jobs/json,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@14671ea7{/jobs/job,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@25fb7246{/jobs/job/json,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@466ceafd{/stages,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a5256b1{/stages/json,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7eb62f0e{/stages/stage,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59a40f6f{/stages/stage/json,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16a5850a{/stages/pool,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1e5213e9{/stages/pool/json,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6600301e{/storage,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f2684c6{/storage/json,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2591dffd{/storage/rdd,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b524dfd{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c350849{/environment,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@671ea5bd{/environment/json,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cdbe094{/executors,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@755f7157{/executors/json,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@114c58f5{/executors/threadDump,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@36d342c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1021bb95{/static,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26dcc406{/,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6d11f8d9{/api,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@496cc67d{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f207b1f{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-04-03 14:45:59 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://sharc-node177.shef.ac.uk:4041
2019-04-03 14:46:00 INFO  SparkContext:54 - Added file file:/home/acp17at/Code/Q2_acp17at.py at file:/home/acp17at/Code/Q2_acp17at.py with timestamp 1554299160087
2019-04-03 14:46:00 INFO  Utils:54 - Copying /home/acp17at/Code/Q2_acp17at.py to /scratch/4047101.1.rse-com6012.q/spark-cd158206-c31a-4854-a1df-a171b5c336b0/userFiles-1264d512-094d-4c12-a070-59cd56a5f4c0/Q2_acp17at.py
2019-04-03 14:46:00 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-04-03 14:46:00 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41577.
2019-04-03 14:46:00 INFO  NettyBlockTransferService:54 - Server created on sharc-node177.shef.ac.uk:41577
2019-04-03 14:46:00 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-04-03 14:46:00 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, sharc-node177.shef.ac.uk, 41577, None)
2019-04-03 14:46:00 INFO  BlockManagerMasterEndpoint:54 - Registering block manager sharc-node177.shef.ac.uk:41577 with 10.5 GB RAM, BlockManagerId(driver, sharc-node177.shef.ac.uk, 41577, None)
2019-04-03 14:46:00 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, sharc-node177.shef.ac.uk, 41577, None)
2019-04-03 14:46:00 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, sharc-node177.shef.ac.uk, 41577, None)
2019-04-03 14:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2292c815{/metrics/json,null,AVAILABLE,@Spark}
2019-04-03 14:46:00 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/acp17at/Code/spark-warehouse/').
2019-04-03 14:46:00 INFO  SharedState:54 - Warehouse path is 'file:/home/acp17at/Code/spark-warehouse/'.
2019-04-03 14:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@429a6267{/SQL,null,AVAILABLE,@Spark}
2019-04-03 14:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b351988{/SQL/json,null,AVAILABLE,@Spark}
2019-04-03 14:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5381e40{/SQL/execution,null,AVAILABLE,@Spark}
2019-04-03 14:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4e47c02f{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-04-03 14:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f7aae8e{/static/sql,null,AVAILABLE,@Spark}
2019-04-03 14:46:00 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-04-03 14:46:03 WARN  Utils:66 - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
2019-04-03 14:46:44 WARN  BLAS:61 - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2019-04-03 14:46:44 WARN  BLAS:61 - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS


Question 2.2(a).............

RMSE for training data:0.003290
RMSE for test data = 0.00331967 